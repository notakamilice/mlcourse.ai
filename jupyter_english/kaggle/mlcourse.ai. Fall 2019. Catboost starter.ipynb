{"cells":[{"metadata":{},"cell_type":"markdown","source":"<center>\n<img src=\"https://habrastorage.org/files/fd4/502/43d/fd450243dd604b81b9713213a247aa20.jpg\" />\n</center> \n     \n## <center>  [mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course \n\n#### <center> Author: [Yury Kashnitsky](https://yorko.github.io) (@yorko) \n\n# <center>Assignment #2. Fall 2019\n## <center> Part 2. Gradient boosting"},{"metadata":{},"cell_type":"markdown","source":"**In this assignment, you're asked to beat a baseline in the [\"Flight delays\" competition](https://www.kaggle.com/c/flight-delays-fall-2018).**\n\nThis time we decided to share a pretty decent CatBoost baseline, you'll have to improve the provided solution.\n\nPrior to working on the assignment, you'd better check out the corresponding course material:\n 1. [Classification, Decision Trees and k Nearest Neighbors](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic03_decision_trees_kNN/topic3_decision_trees_kNN.ipynb?flush_cache=true), the same as an interactive web-based [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-3-decision-trees-and-knn) \n 2. Ensembles:\n  - [Bagging](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part1_bagging.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-1-bagging)\n  - [Random Forest](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part2_random_forest.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-2-random-forest)\n  - [Feature Importance](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic05_ensembles_random_forests/topic5_part3_feature_importance.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-5-ensembles-part-3-feature-importance)\n 3. - [Gradient boosting](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic10_boosting/topic10_gradient_boosting.ipynb?flush_cache=true), the same as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-10-gradient-boosting) \n   - Logistic regression, Random Forest, and LightGBM in the \"Kaggle Forest Cover Type Prediction\" competition: [Kernel](https://www.kaggle.com/kashnitsky/topic-10-practice-with-logit-rf-and-lightgbm) \n 4. You can also practice with demo assignments, which are simpler and already shared with solutions:\n  - \"Decision trees with a toy task and the UCI Adult dataset\": [assignment](https://www.kaggle.com/kashnitsky/a3-demo-decision-trees) + [solution](https://www.kaggle.com/kashnitsky/a3-demo-decision-trees-solution)\n  - \"Logistic Regression and Random Forest in the credit scoring problem\": [assignment](https://www.kaggle.com/kashnitsky/assignment-5-logit-and-rf-for-credit-scoring) + [solution](https://www.kaggle.com/kashnitsky/a5-demo-logit-and-rf-for-credit-scoring-sol)\n 5. There are also 7 video lectures on trees, forests, boosting and their applications: [mlcourse.ai/video](https://mlcourse.ai/video) \n 6. mlcourse.ai tutorials on [categorical feature encoding](https://www.kaggle.com/waydeherman/tutorial-categorical-encoding) (by Wayde Herman) and [CatBoost](https://www.kaggle.com/mitribunskiy/tutorial-catboost-overview) (by Mikhail Tribunskiy)\n 7. Last but not the least: [Public Kernels](https://www.kaggle.com/c/flight-delays-fall-2018/notebooks) in this competition\n\n### Your task is to:\n 1. beat **\"A2 baseline (10 credits)\"** on Public LB (**0.75914** LB score)\n 2. rename your [team](https://www.kaggle.com/c/flight-delays-fall-2018/team) in full accordance with A1 and the [course rating](https://docs.google.com/spreadsheets/d/15e1K0tg5ponA5R6YQkZfihrShTDLAKf5qeKaoVCiuhQ/) (to appear on 16.09.2019)\n \nThis task is intended to be relatively easy. Here you are not required to upload your reproducible solution.\n \n### <center> Deadline for A2: 2019 October 6, 20:59 CET (London time)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom catboost import CatBoostClassifier","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Read the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH_TO_DATA = Path('../input/flight-delays-fall-2018/')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(PATH_TO_DATA / 'flight_delays_train.csv')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"  Month DayofMonth DayOfWeek  DepTime UniqueCarrier Origin Dest  Distance  \\\n0   c-8       c-21       c-7     1934            AA    ATL  DFW       732   \n1   c-4       c-20       c-3     1548            US    PIT  MCO       834   \n2   c-9        c-2       c-5     1422            XE    RDU  CLE       416   \n3  c-11       c-25       c-6     1015            OO    DEN  MEM       872   \n4  c-10        c-7       c-6     1828            WN    MDW  OMA       423   \n\n  dep_delayed_15min  \n0                 N  \n1                 N  \n2                 N  \n3                 N  \n4                 Y  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Month</th>\n      <th>DayofMonth</th>\n      <th>DayOfWeek</th>\n      <th>DepTime</th>\n      <th>UniqueCarrier</th>\n      <th>Origin</th>\n      <th>Dest</th>\n      <th>Distance</th>\n      <th>dep_delayed_15min</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>c-8</td>\n      <td>c-21</td>\n      <td>c-7</td>\n      <td>1934</td>\n      <td>AA</td>\n      <td>ATL</td>\n      <td>DFW</td>\n      <td>732</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>c-4</td>\n      <td>c-20</td>\n      <td>c-3</td>\n      <td>1548</td>\n      <td>US</td>\n      <td>PIT</td>\n      <td>MCO</td>\n      <td>834</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>c-9</td>\n      <td>c-2</td>\n      <td>c-5</td>\n      <td>1422</td>\n      <td>XE</td>\n      <td>RDU</td>\n      <td>CLE</td>\n      <td>416</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>c-11</td>\n      <td>c-25</td>\n      <td>c-6</td>\n      <td>1015</td>\n      <td>OO</td>\n      <td>DEN</td>\n      <td>MEM</td>\n      <td>872</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>c-10</td>\n      <td>c-7</td>\n      <td>c-6</td>\n      <td>1828</td>\n      <td>WN</td>\n      <td>MDW</td>\n      <td>OMA</td>\n      <td>423</td>\n      <td>Y</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(PATH_TO_DATA / 'flight_delays_test.csv')","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"  Month DayofMonth DayOfWeek  DepTime UniqueCarrier Origin Dest  Distance\n0   c-7       c-25       c-3      615            YV    MRY  PHX       598\n1   c-4       c-17       c-2      739            WN    LAS  HOU      1235\n2  c-12        c-2       c-7      651            MQ    GSP  ORD       577\n3   c-3       c-25       c-7     1614            WN    BWI  MHT       377\n4   c-6        c-6       c-3     1505            UA    ORD  STL       258","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Month</th>\n      <th>DayofMonth</th>\n      <th>DayOfWeek</th>\n      <th>DepTime</th>\n      <th>UniqueCarrier</th>\n      <th>Origin</th>\n      <th>Dest</th>\n      <th>Distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>c-7</td>\n      <td>c-25</td>\n      <td>c-3</td>\n      <td>615</td>\n      <td>YV</td>\n      <td>MRY</td>\n      <td>PHX</td>\n      <td>598</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>c-4</td>\n      <td>c-17</td>\n      <td>c-2</td>\n      <td>739</td>\n      <td>WN</td>\n      <td>LAS</td>\n      <td>HOU</td>\n      <td>1235</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>c-12</td>\n      <td>c-2</td>\n      <td>c-7</td>\n      <td>651</td>\n      <td>MQ</td>\n      <td>GSP</td>\n      <td>ORD</td>\n      <td>577</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>c-3</td>\n      <td>c-25</td>\n      <td>c-7</td>\n      <td>1614</td>\n      <td>WN</td>\n      <td>BWI</td>\n      <td>MHT</td>\n      <td>377</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>c-6</td>\n      <td>c-6</td>\n      <td>c-3</td>\n      <td>1505</td>\n      <td>UA</td>\n      <td>ORD</td>\n      <td>STL</td>\n      <td>258</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Create only one feature - “flight” (this you need to improve - add more features)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['flight'] = train_df['Origin'] + '-->' + train_df['Dest']\ntest_df['flight'] = test_df['Origin'] + '-->' + test_df['Dest']","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Remember indexes of categorical features (to be passed to CatBoost)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"categ_feat_idx = np.where(train_df.drop('dep_delayed_15min', axis=1).dtypes == 'object')[0]\ncateg_feat_idx","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Allocate a hold-out set (a.k.a. a validation set) to validate the model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_df.drop('dep_delayed_15min', axis=1).values\ny_train = train_df['dep_delayed_15min'].map({'Y': 1, 'N': 0}).values\nX_test = test_df.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_part, X_valid, y_train_part, y_valid = train_test_split(X_train, y_train, \n                                                                test_size=0.3, \n                                                                random_state=17)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train Catboost with default arguments, passing only the indexes of categorical features.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ctb = CatBoostClassifier(random_seed=17, silent=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nctb.fit(X_train_part, y_train_part,\n        cat_features=categ_feat_idx);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ctb_valid_pred = ctb.predict_proba(X_valid)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We got some 0.756 ROC AUC on the hold-out set.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(y_valid, ctb_valid_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train on the whole train set, make prediction on the test set. We got ~0.734 in the competition - \"Catboost starter\" baseline**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nctb.fit(X_train, y_train,\n        cat_features=categ_feat_idx);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ctb_test_pred = ctb.predict_proba(X_test)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    \n    sample_sub = pd.read_csv(PATH_TO_DATA / 'sample_submission.csv', \n                             index_col='id')\n    sample_sub['dep_delayed_15min'] = ctb_test_pred\n    sample_sub.to_csv('ctb_pred.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!head ctb_pred.csv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now's your turn! Go and improve the model to beat **\"A2 baseline (10 credits)\"** - **0.75914** LB score. It's crucial to come up with some good features. \n\nFor discussions, stick to the **#a2_kaggle_fall2019** thread in the **mlcourse_ai_news** [ODS Slack](http://opendatascience.slack.com) channel. Serhii Romanenko (@serhii_romanenko) will be there to help. \n\nWelcome to Kaggle!\n\n<img src='https://habrastorage.org/webt/fs/42/ms/fs42ms0r7qsoj-da4x7yfntwrbq.jpeg' width=50%>\n*from the [\"Nerd Laughing Loud\"](https://www.kaggle.com/general/76963) thread.*"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}